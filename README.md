<h2> Synthetic data  </h2>

- Synthetic data refers to artificially generated information that mimics the characteristics of real-world data, but is created through computational methods rather than being collected from actual events or sources.
- This simulated data is valuable for testing, training, and - research purposes, as it overcomes privacy concerns, data scarcity, and logistical constraints associated with using genuine data.

<b>Advantages of Synthetic Data </b><br/>
- Enhanced Privacy and Security: Eliminates risk of personal data breaches.<br/>
- Regulatory Simplification: Ensures compliance with stringent data protection laws.<br/>
- Accelerated Development and Unrestricted Access: Enables rapid prototyping, testing, and access when real data is unavailable.<br/>
- Data Enrichment and Scenario Customization : Augments datasets and creates specific or rare scenarios for improved machine learning.<br/>
- Controlled Testing: Allows simulation of specific conditions for experimentation.<br/>
- Improved Model Robustness: Leads to better-performing and generalizing AI models.<br/>
- Cost Efficiency: Offers a cost-effective alternative to real-world data collection.<br/>
<br/>
Point to consider: Synthetic data should be used carefully, as it may not always capture real-world complexities.<br/>

<h2> Large Language Model for synthetic data generation for text data</h2> 
Language models have exploded on the internet ever since ChatGPT came out, and rightfully so. They can write essays, code entire programs, and even make memes. They are particularly useful to generate datasets on unstructured data.<br/>
<br/>
Synthetic data generation reference : (https://towardsdatascience.com/create-a-synthetic-dataset-using-llama-3-1-405b-for-instruction-fine-tuning-9afc22fb6eef) <br/>
<br/>

Dataset Used: wikiAll data <br/>
https://ucsb.box.com/s/ap23l8gafpezf4tq3wapr6u8241zz358     <br/>

<h2> LLMs used in this project</h2> 
Leveraged open-source Large Language Models (LLMs), specifically LLaMA3 (8B) and Gemma2 (2B), via Ollama <br/>
<br/>
<b>LLama3 8b </b><br/>
- Utilized LLaMA3's advanced language understanding capabilities to generate high-quality synthetic data for QA systems.<br/> 
- Owner: Developed and maintained by Meta AI (formerly Facebook AI).<br/>
https://ollama.com/library/llama3<br/>
<br/>

<b>Google Gemma2:2b</b><br/>
- Employed Gemma2's innovative language generation capabilities to produce diverse and relevant synthetic data..<br/>
- Owner:  Developed and maintained by Google.<br/>
https://developers.googleblog.com/en/gemma-explained-new-in-gemma-2/


<h2> Evaluation of Generated Synthetic Data:: LLM as Judge </h2>
- Employed Gemma2 to evaluate data generated by LLaMA3 and alternatively utilized LLaMA3 to evaluate the data generated by Gemma2.<br/>

<h2> Observations and Insights</h2>
- Benchmarking results: Gemma2 (2B) outperformed LLaMA3 (8B) in quality and speed on our dataset.<br/>
- Feedback loop opportunity: Generated data feedback can be utilized to refine and enhance data quality, addressing existing gaps..<br/>

<h3> Future work </h3>
- Iterative Refinement: Leverage generated data feedback to refine and enhance data quality, addressing existing gaps and improving overall model performance..<br/>
- Explore combining outputs from multiple LLMs (e.g., LLaMA3, Gemma2) to create more diverse and robust synthetic data..<br/>
- Investigate adapting the synthetic data generation process to specific domains (e.g., medical, financial) to improve relevance and accuracy..<br/>
- Evaluation Metrics: Develop and integrate more comprehensive evaluation metrics to assess synthetic data quality and effectiveness.

<h2> Framework used </h2>
- Langchain <br/>

<h2> Acknowledgments </h2>
- I acknowledge the developers of LLaMA3 (Meta AI) and Gemma2(Google) for providing access to their models and APIs.

<h2> How to run This Application</h2> 
**Note:** Download and install the LLaMA 3 model (8B) from the official website: <br/>
https://ollama.com/blog/llama3 <br/>
https://ollama.com/blog/gemma2 <br/>
Install the OLLAMA server by following the instructions on the above website <br/><br/>

<b> Running the Application: </b> <br/>
Start the OLLAMA server by running the command 'ollama serve' in your terminal <br/>
By default ollama server runs in the port (11434)<br/>

1. Clone this git repository from command prompt<br/>
git clone https://github.com/padmapria/LLM-Synthetic-Data-Generation-for-text-Data.git    
cd Synthatic_Data_Generation_with_llm    

2. Create conda environment 
3. Install dependencies given in the requirements.txt  
4. Run the notebook
