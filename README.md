
<h2> Large Language Model for synthetic data generation for text data</h2> 
Language models have exploded on the internet ever since ChatGPT came out, and rightfully so. They can write essays, code entire programs, and even make memes. They are particularly useful to generate datasets on unstructured data.<br/>
<br/>
Synthetic data generation reference : (https://towardsdatascience.com/create-a-synthetic-dataset-using-llama-3-1-405b-for-instruction-fine-tuning-9afc22fb6eef) <br/>
<br/>

Dataset Used: wikiAll data <br/>
https://ucsb.box.com/s/ap23l8gafpezf4tq3wapr6u8241zz358     <br/>

<h2> LLMs used in this project</h2> 
Leveraged open-source Large Language Models (LLMs), specifically LLaMA3 (8B) and Gemma2 (2B), via Ollama <br/>
<br/>
<b>LLama3 8b </b><br/>
- Utilized LLaMA3's advanced language understanding capabilities to generate high-quality synthetic data for QA systems.<br/>
- Owner: Developed and maintained by Meta AI (formerly Facebook AI).<br/>
<br/>

<b>Gemma2:2b</b><br/>
- Employed Gemma2's innovative language generation capabilities to produce diverse and relevant synthetic data..<br/>
- Integrated Gemma2's API to augment our synthetic data generation, improving the robustness of our QA system.<br/>

<h2> Evaluation of Generated Synthetic Data</h2>
- Employed Gemma2 to evaluate data generated by LLaMA3 and alternatively utilized LLaMA3 to evaluate the data generated by Gemma2.<br/>

<h2> Observations and Insights</h2>
- Benchmarking results: Gemma2 (2B) outperformed LLaMA3 (8B) in quality and speed on our dataset.<br/>
- Feedback loop opportunity: Generated data feedback can be utilized to refine and enhance data quality, addressing existing gaps..<br/>

<h3> Future work </h3>
- Iterative Refinement: Leverage generated data feedback to refine and enhance data quality, addressing existing gaps and improving overall model performance..<br/>
- Explore combining outputs from multiple LLMs (e.g., LLaMA3, Gemma2) to create more diverse and robust synthetic data..<br/>
- Investigate adapting the synthetic data generation process to specific domains (e.g., medical, financial) to improve relevance and accuracy..<br/>
- Evaluation Metrics: Develop and integrate more comprehensive evaluation metrics to assess synthetic data quality and effectiveness.

<h2> Acknowledgments </h2>
- I acknowledge the developers of LLaMA3 (Meta AI) and Gemma2 for providing access to their models and APIs.

<h2> How to run This Application</h2> 
**Note:** Download and install the LLaMA 3 model (8B) from the official website: <br/>
https://ollama.com/blog/llama3 <br/>
https://ollama.com/blog/gemma2 <br/>
Install the OLLAMA server by following the instructions on the above website <br/><br/>

<b> Running the Application: </b> <br/>
Start the OLLAMA server by running the command 'ollama serve' in your terminal <br/>
By default ollama server runs in the port (11434)<br/>

1. Clone this git repository from command prompt<br/>
git clone https://github.com/padmapria/LLM-Synthetic-Data-Generation-for-text-Data.git    
cd Synthatic_Data_Generation_with_llm    

2. Create conda environment 
3. Install dependencies given in the requirements.txt  
4. Run the notebook
